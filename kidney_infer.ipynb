{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tifffile as tiff\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import *\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "from tqdm import tqdm\n",
    "print('tensorflow version:', tf.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print('device available:', gpu_device)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "KAGGLE = False\n",
    "VER = 'v2'\n",
    "if KAGGLE:\n",
    "    DATA_PATH = '../input/hubmap-kidney-segmentation'\n",
    "    MDLS_PATH = f'../input/kidney-models-{VER}'\n",
    "else:\n",
    "    DATA_PATH = './data'\n",
    "    MDLS_PATH = f'./models_{VER}'\n",
    "THRESHOLD = .5\n",
    "PRED_BATCH_SIZE = 256\n",
    "TTAS = [1.25, 1.5, 2]\n",
    "SUB_PATH = f'{DATA_PATH}/test' if TEST else f'{DATA_PATH}/train'\n",
    "CACHE_PATH = './cache_kidney'\n",
    "if not os.path.exists(CACHE_PATH):\n",
    "    os.mkdir(CACHE_PATH)\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for m, enc in enumerate(encs):\n",
    "        if isinstance(enc, np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s) // 2):\n",
    "            start = int(s[2 * i]) - 1\n",
    "            length = int(s[2 * i + 1])\n",
    "            img[start : start + length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def rle_encode_less_memory(img):\n",
    "    pixels = img.T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1):\n",
    "    return (1 - dice_coef(y_true, y_pred, smooth))\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def get_model(backbone, path, input_shape, classes=1, learning_rate=.001):\n",
    "    if backbone == 'efficientnetb0':\n",
    "        weights = f'{path}/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "    elif backbone == 'efficientnetb1':\n",
    "        weights = f'{path}/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "    elif backbone == 'efficientnetb2':\n",
    "        weights = f'{path}/efficientnet-b2_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "    else:\n",
    "        raise AttributeError('mode parameter error')\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model = Unet(backbone_name=backbone,\n",
    "                 input_shape=input_shape,\n",
    "                 classes=classes, \n",
    "                 activation='sigmoid',\n",
    "                 encoder_weights=weights)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=bce_dice_loss, \n",
    "                  metrics=[dice_coef])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles(img_name, path, params, mode=1):\n",
    "    img = tiff.imread(os.path.join(path, img_name + '.tiff'))\n",
    "    if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "    print(img_name, 'read:', img.shape)\n",
    "    shape = img.shape\n",
    "    tile_size = int(params['img_size'] * mode)\n",
    "    pad0 = (\n",
    "        params['resize'] * tile_size\n",
    "        - shape[0] % (params['resize'] * tile_size)\n",
    "    ) % (\n",
    "        params['resize'] * tile_size\n",
    "    )\n",
    "    pad1 = (\n",
    "        params['resize'] * tile_size\n",
    "        - shape[1] % (params['resize'] * tile_size)\n",
    "    ) % (\n",
    "        params['resize'] * tile_size\n",
    "    )\n",
    "    img = np.pad(img, \n",
    "                 [[pad0 // 2, pad0 - pad0 // 2],\n",
    "                  [pad1 // 2, pad1 - pad1 // 2],\n",
    "                  [0, 0]],\n",
    "                 constant_values=0)\n",
    "    print(img_name, 'padded:', img.shape)\n",
    "    img = cv2.resize(img,\n",
    "                     (img.shape[1] // params['resize'], img.shape[0] // params['resize']),\n",
    "                     interpolation=cv2.INTER_AREA)\n",
    "    img = img.reshape(img.shape[0] // tile_size, \n",
    "                      tile_size, \n",
    "                      img.shape[1] // tile_size, \n",
    "                      tile_size, \n",
    "                      3)\n",
    "    print(img_name, 'resized and reshaped:', img.shape)\n",
    "    img = img.transpose(0, 2, 1, 3, 4).reshape(-1, tile_size, tile_size, 3) \n",
    "    print(img_name, 'finally reshaped:', img.shape)\n",
    "    return img, shape, pad0, pad1\n",
    "\n",
    "def restore_mask(msk, shape, pad0, pad1, params, mode=1):\n",
    "    tile_size = int(params['img_size'] * mode)\n",
    "    msk = np.squeeze(msk)\n",
    "    print('mask init:', msk.shape)\n",
    "    msk = msk.reshape(\n",
    "        int((shape[0] + pad0) / tile_size / params['resize']), \n",
    "        int((shape[1] + pad1) / tile_size / params['resize']), \n",
    "        tile_size, \n",
    "        tile_size\n",
    "    )\n",
    "    msk = msk.transpose(0, 2, 1, 3)\n",
    "    print('mask reshaped and transposed:', msk.shape)\n",
    "    msk = msk.reshape(\n",
    "        int((shape[0] + pad0) / params['resize']), \n",
    "        int((shape[1] + pad1) / params['resize'])\n",
    "    )\n",
    "    print('mask reshaped:', msk.shape)\n",
    "    msk = (msk > THRESHOLD).astype(np.int8)\n",
    "    msk = cv2.resize(\n",
    "        msk,\n",
    "        (msk.shape[1] * params['resize'], msk.shape[0] * params['resize']),\n",
    "        interpolation=cv2.INTER_NEAREST\n",
    "    )\n",
    "    print('mask resized:', msk.shape)\n",
    "    msk = msk[\n",
    "        pad0 // 2 : -(pad0 - pad0 // 2) if pad0 > 0 else (shape[0] + pad0),\n",
    "        pad1 // 2 : -(pad1 - pad1 // 2) if pad1 > 0 else (shape[1] + pad1)\n",
    "    ]\n",
    "    print('mask finally un-padded:', msk.shape)\n",
    "    return msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MDLS_PATH}/params.json') as file:\n",
    "    params = json.load(file)\n",
    "print('loaded params:', params)\n",
    "    \n",
    "imgs_idxs = [x.replace('.tiff', '') for x in os.listdir(SUB_PATH) if '.tiff' in x]\n",
    "print('images idxs:', imgs_idxs)\n",
    "\n",
    "for i_mode, mode in enumerate(TTAS):\n",
    "    for img_idx in imgs_idxs:\n",
    "        print('-' * 20, img_idx, '-' * 20)\n",
    "        cache_dict = {}\n",
    "        img, shape, pad0, pad1 = get_tiles(img_idx, SUB_PATH, params, mode) \n",
    "        cache_dict['img'], cache_dict['shape'] = img, shape\n",
    "        cache_dict['pad0'], cache_dict['pad1'] = pad0, pad1\n",
    "        file_name = f'{CACHE_PATH}/{img_idx}_m{i_mode}.pickle'\n",
    "        with open(file_name, 'wb') as handle:\n",
    "            pickle.dump(cache_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        del img, shape, pad0, pad1; gc.collect()\n",
    "        print(img_idx, 'done | saved to', file_name)\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = []\n",
    "for i_mode, mode in enumerate(TTAS):\n",
    "    print('=' * 20, 'tta:', i_mode, '=' * 20)\n",
    "    img_indexes = []\n",
    "    img_rles = []\n",
    "    img_shapes = []\n",
    "    for img_idx in imgs_idxs:\n",
    "        print('-' * 20, img_idx, '-' * 20)\n",
    "        file_name = f'{CACHE_PATH}/{img_idx}_m{i_mode}.pickle'\n",
    "        with open(file_name, 'rb') as handle:\n",
    "            cache_dict = pickle.load(handle)\n",
    "        img, shape = cache_dict['img'], cache_dict['shape']\n",
    "        pad0, pad1 = cache_dict['pad0'], cache_dict['pad1']\n",
    "        del cache_dict\n",
    "        msk_pred = np.zeros((len(img), img.shape[1], img.shape[2], 1))\n",
    "        folds = list(range(params['folds']))\n",
    "        #folds = [0, 1]\n",
    "        for n_fold in folds:\n",
    "            checkpoint_path = f'{MDLS_PATH}/model_{n_fold}.hdf5'\n",
    "            model = get_model(\n",
    "                params['backbone'], \n",
    "                MDLS_PATH,\n",
    "                input_shape=(int(params['img_size'] * mode), \n",
    "                             int(params['img_size'] * mode), 3)\n",
    "            )\n",
    "            model.load_weights(checkpoint_path)\n",
    "            print('loaded:', checkpoint_path, end=' ')\n",
    "            batch = int(PRED_BATCH_SIZE / mode)\n",
    "            msk_pred_fold = np.zeros((len(img), img.shape[1], img.shape[2], 1))\n",
    "            for i in range(len(img) // batch + 1):\n",
    "                if i * batch < len(img):\n",
    "                    imgs_batch = np.array([\n",
    "                        cv2.cvtColor(img[j, ], cv2.COLOR_BGR2RGB) / 255\n",
    "                        for j in range(i * batch, min((i+1) * batch, len(img)))\n",
    "                    ])\n",
    "                    msk_pred_fold[i * batch : min((i+1) * batch, len(img)), ] = model.predict(imgs_batch)\n",
    "            print('done')\n",
    "            msk_pred = msk_pred + msk_pred_fold / len(folds)\n",
    "            del model, msk_pred_fold, imgs_batch; gc.collect()\n",
    "        del img; gc.collect()\n",
    "        msk_pred = restore_mask(msk_pred, shape, pad0, pad1, params, mode)\n",
    "        rle = rle_encode_less_memory(msk_pred)\n",
    "        img_indexes.append(img_idx)\n",
    "        img_rles.append(rle)\n",
    "        img_shapes.append(shape)\n",
    "        del msk_pred, rle; gc.collect()\n",
    "        print(img_idx, 'tta', i_mode, 'done')\n",
    "    sub_list.append(img_indexes)\n",
    "    sub_list.append(img_rles)\n",
    "    sub_list.append(img_shapes)\n",
    "shutil.rmtree(CACHE_PATH)\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_masks = []\n",
    "for i, row in pd.DataFrame(sub_list).T.iterrows():\n",
    "    print('processing', row[0], end=' ')\n",
    "    shape = [int(row[2][0]), int(row[2][1])]\n",
    "    mask = np.zeros(shape, dtype=np.int8)\n",
    "    for i in range(len(TTAS)):\n",
    "        mask = mask + enc2mask([row[i * 3 + 1]], (shape[1], shape[0]))\n",
    "    tta_masks.append(rle_encode_less_memory((mask >= len(TTAS) - 1).astype(np.int8)))\n",
    "    del mask; gc.collect()\n",
    "    print('done')\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list.append(tta_masks)\n",
    "df_sub = pd.DataFrame(sub_list).T.iloc[:, [0, -1]]\n",
    "df_sub.columns = ['id', 'predicted']\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST:\n",
    "    df_masks = pd.read_csv(f'{DATA_PATH}/train.csv').set_index('id')\n",
    "    idx = df_sub.iloc[0].id\n",
    "    img = tiff.imread(os.path.join(SUB_PATH, idx + '.tiff'))\n",
    "    if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "    msk_p = enc2mask([df_sub.iloc[0].predicted], (img.shape[1], img.shape[0]))\n",
    "    msk = enc2mask([df_masks.loc[idx, 'encoding']], (img.shape[1], img.shape[0]))\n",
    "    print(img.shape)\n",
    "    print(msk_p.shape)\n",
    "    print(msk.shape)\n",
    "    \n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(msk_p, alpha=.4)\n",
    "    plt.imshow(msk, alpha=.2)\n",
    "    plt.title(idx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
