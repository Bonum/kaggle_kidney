{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tifffile as tiff\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import *\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "from tqdm import tqdm\n",
    "print('tensorflow version:', tf.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    for gpu_device in gpu_devices:\n",
    "        print('device available:', gpu_device)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True\n",
    "KAGGLE = False\n",
    "VER = 'v0'\n",
    "if KAGGLE:\n",
    "    DATA_PATH = '../input/hubmap-kidney-segmentation'\n",
    "    MDLS_PATH = f'../input/kidney-models-{VER}'\n",
    "else:\n",
    "    DATA_PATH = './data'\n",
    "    MDLS_PATH = f'./models_{VER}'\n",
    "THRESHOLD = .5\n",
    "SUB_PATH = f'{DATA_PATH}/test' if TEST else f'{DATA_PATH}/train'\n",
    "CACHE_PATH = './cache_kidney'\n",
    "if not os.path.exists(CACHE_PATH):\n",
    "    os.mkdir(CACHE_PATH)\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc2mask(encs, shape):\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for m, enc in enumerate(encs):\n",
    "        if isinstance(enc, np.float) and np.isnan(enc): continue\n",
    "        s = enc.split()\n",
    "        for i in range(len(s) // 2):\n",
    "            start = int(s[2 * i]) - 1\n",
    "            length = int(s[2 * i + 1])\n",
    "            img[start : start + length] = 1 + m\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def rle_encode_less_memory(img):\n",
    "    pixels = img.T.flatten()\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1):\n",
    "    return (1 - dice_coef(y_true, y_pred, smooth))\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def get_model(backbone, path, input_shape, classes=1, learning_rate=.001):\n",
    "    if backbone == 'efficientnetb0':\n",
    "        weights = f'{path}/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "    elif backbone == 'efficientnetb1':\n",
    "        weights = f'{path}/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'\n",
    "    else:\n",
    "        raise AttributeError('mode parameter error')\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model = Unet(backbone_name=backbone,\n",
    "                 input_shape=input_shape,\n",
    "                 classes=classes, \n",
    "                 activation='sigmoid',\n",
    "                 encoder_weights=weights)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=bce_dice_loss, \n",
    "                  metrics=[dice_coef])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles(img_name, path, params):\n",
    "    img = tiff.imread(os.path.join(path, img_name + '.tiff'))\n",
    "    if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "    print(img_name, 'read:', img.shape)\n",
    "    shape = img.shape\n",
    "    pad0 = (\n",
    "        params['resize'] * params['img_size'] \n",
    "        - shape[0] % (params['resize'] * params['img_size'])\n",
    "    ) % (\n",
    "        params['resize'] * params['img_size']\n",
    "    )\n",
    "    pad1 = (\n",
    "        params['resize'] * params['img_size']\n",
    "        - shape[1] % (params['resize'] * params['img_size'])\n",
    "    ) % (\n",
    "        params['resize'] * params['img_size']\n",
    "    )\n",
    "    img = np.pad(img, \n",
    "                 [[pad0 // 2, pad0 - pad0 // 2],\n",
    "                  [pad1 // 2, pad1 - pad1 // 2],\n",
    "                  [0, 0]],\n",
    "                 constant_values=0)\n",
    "    print(img_name, 'padded:', img.shape)\n",
    "    img = cv2.resize(img,\n",
    "                     (img.shape[1] // params['resize'], img.shape[0] // params['resize']),\n",
    "                     interpolation=cv2.INTER_AREA)\n",
    "    img = img.reshape(img.shape[0] // params['img_size'], \n",
    "                      params['img_size'], \n",
    "                      img.shape[1] // params['img_size'], \n",
    "                      params['img_size'], \n",
    "                      3)\n",
    "    print(img_name, 'resized and reshaped:', img.shape)\n",
    "    img = img.transpose(0, 2, 1, 3, 4).reshape(-1, params['img_size'], params['img_size'], 3) \n",
    "    print(img_name, 'finally reshaped:', img.shape)\n",
    "    return img, shape, pad0, pad1\n",
    "\n",
    "def restore_mask(msk, shape, pad0, pad1, params):\n",
    "    msk = np.squeeze(msk)\n",
    "    print('mask init:', msk.shape)\n",
    "    msk = msk.reshape(\n",
    "        int((shape[0] + pad0) / params['img_size'] / params['resize']), \n",
    "        int((shape[1] + pad1) / params['img_size'] / params['resize']), \n",
    "        params['img_size'], \n",
    "        params['img_size']\n",
    "    )\n",
    "    msk = msk.transpose(0, 2, 1, 3)\n",
    "    print('mask reshaped and transposed:', msk.shape)\n",
    "    msk = msk.reshape(\n",
    "        int((shape[0] + pad0) / params['resize']), \n",
    "        int((shape[1] + pad1) / params['resize'])\n",
    "    )\n",
    "    print('mask reshaped:', msk.shape)\n",
    "    msk = (msk > THRESHOLD).astype(np.int8)\n",
    "    msk = cv2.resize(\n",
    "        msk,\n",
    "        (msk.shape[1] * params['resize'], msk.shape[0] * params['resize']),\n",
    "        interpolation=cv2.INTER_NEAREST\n",
    "    )\n",
    "    print('mask resized:', msk.shape)\n",
    "    msk = msk[\n",
    "        pad0 // 2 : -(pad0 - pad0 // 2) if pad0 > 0 else (shape[0] + pad0),\n",
    "        pad1 // 2 : -(pad1 - pad1 // 2) if pad1 > 0 else (shape[1] + pad1)\n",
    "    ]\n",
    "    print('mask finally un-padded:', msk.shape)\n",
    "    return msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MDLS_PATH}/params.json') as file:\n",
    "    params = json.load(file)\n",
    "print('loaded params:', params)\n",
    "    \n",
    "imgs_idxs = [x.replace('.tiff', '') for x in os.listdir(SUB_PATH) if '.tiff' in x]\n",
    "print('images idxs:', imgs_idxs)\n",
    "\n",
    "for img_idx in imgs_idxs:\n",
    "    print('-' * 20, img_idx, '-' * 20)\n",
    "    cache_dict = {}\n",
    "    img, shape, pad0, pad1 = get_tiles(img_idx, SUB_PATH, params) \n",
    "    cache_dict['img'], cache_dict['shape'] = img, shape\n",
    "    cache_dict['pad0'], cache_dict['pad1'] = pad0, pad1\n",
    "    with open(f'{CACHE_PATH}/{img_idx}.pickle', 'wb') as handle:\n",
    "        pickle.dump(cache_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    del img, shape, pad0, pad1\n",
    "    gc.collect()\n",
    "    print(img_idx, 'done')\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dict = {}\n",
    "for img_idx in imgs_idxs:\n",
    "    print('-' * 20, img_idx, '-' * 20)\n",
    "    with open(f'{CACHE_PATH}/{img_idx}.pickle', 'rb') as handle:\n",
    "        cache_dict = pickle.load(handle)\n",
    "    img, shape = cache_dict['img'], cache_dict['shape']\n",
    "    pad0, pad1 = cache_dict['pad0'], cache_dict['pad1']\n",
    "    del cache_dict\n",
    "    msk_pred = np.zeros((len(img), img.shape[1], img.shape[2], 1))\n",
    "    folds = list(range(params['folds']))\n",
    "    folds = [0, 1]\n",
    "    for n_fold in folds:\n",
    "        checkpoint_path = f'{MDLS_PATH}/model_{n_fold}.hdf5'\n",
    "        model = get_model(\n",
    "            params['backbone'], \n",
    "            MDLS_PATH,\n",
    "            input_shape=(params['img_size'], params['img_size'], 3)\n",
    "        )\n",
    "        model.load_weights(checkpoint_path)\n",
    "        print('loaded:', checkpoint_path, end=' ')\n",
    "        batch = params['batch_size'] * 16\n",
    "        msk_pred_fold = np.zeros((len(img), img.shape[1], img.shape[2], 1))\n",
    "        for i in range(len(img) // batch + 1):\n",
    "            if i * batch < len(img):\n",
    "                imgs_batch = np.array([\n",
    "                    cv2.cvtColor(img[j, ], cv2.COLOR_BGR2RGB) / 255\n",
    "                    for j in range(i * batch, min((i+1) * batch, len(img)))\n",
    "                ])\n",
    "                msk_pred_fold[i * batch : min((i+1) * batch, len(img)), ] = model.predict(imgs_batch)\n",
    "        print('done')\n",
    "        msk_pred = msk_pred + msk_pred_fold / len(folds)\n",
    "        del model, msk_pred_fold, imgs_batch\n",
    "        gc.collect()\n",
    "    del img\n",
    "    gc.collect()\n",
    "    msk_pred = restore_mask(msk_pred, shape, pad0, pad1, params)\n",
    "    rle = rle_encode_less_memory((msk_pred > THRESHOLD).astype(np.int8))\n",
    "    sub_dict[img_idx] = rle\n",
    "    del msk_pred, rle\n",
    "    gc.collect()\n",
    "shutil.rmtree(CACHE_PATH)\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_masks = pd.read_csv(f'{DATA_PATH}/train.csv').set_index('id')\n",
    "df_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST:\n",
    "    print(sub_dict.keys())\n",
    "    idx = list(sub_dict.keys())[0]\n",
    "    img = tiff.imread(os.path.join(SUB_PATH, idx + '.tiff'))\n",
    "    if len(img.shape) == 5: img = np.transpose(img.squeeze(), (1, 2, 0))\n",
    "    msk_p = enc2mask([sub_dict[idx]], (img.shape[1], img.shape[0]))\n",
    "    msk = enc2mask([df_masks.loc[idx, 'encoding']], (img.shape[1], img.shape[0]))\n",
    "    print(img.shape)\n",
    "    print(msk_p.shape)\n",
    "    print(msk.shape)\n",
    "    \n",
    "    plt.figure(figsize=(16, 16))\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(msk_p, alpha=.4)\n",
    "    plt.imshow(msk, alpha=.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame.from_dict(sub_dict, orient='index', columns=['predicted'])\n",
    "df_sub.index.names = ['id']\n",
    "df_sub.to_csv('submission.csv')\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
